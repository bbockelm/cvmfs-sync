#!/usr/bin/python

import os
import pwd
import time
import errno
import optparse
import urlparse
import collections

import classad
import htcondor
import XRootD.client

htcondor.enable_classad_extensions()

g_acct_grp = "cms.other.t3"

def parse_opts():
    parser = optparse.OptionParser(usage="%prog [options] src1 [src2 ...] dest")
    parser.add_option("-f", "--failed", dest="failed",
                      help="Output filename for list of failed directories")
    parser.add_option("--dryrun", dest="dryrun", action="store_true",
                      help="Dry-run; do not actually submit jobs",
                      default=False)

    opts, args = parser.parse_args()
    if len(args) < 2:
        print >> sys.stderr, "Need at least one source and destination"
        parser.print_usage()
        sys.exit(1)

    return opts, args


def process_dir(base_url, directory):
    fs = XRootD.client.FileSystem(base_url)
    worklist = [directory]
    filelist = collections.defaultdict(int)
    base_len = len(directory)
    while worklist:
        cwd = worklist.pop()
        print "Processing", cwd
        status, dirlist = fs.dirlist("/" + cwd,
                                    flags=XRootD.client.flags.DirListFlags.STAT)
        if status.status:
            raise Exception("Failed to list directory")
        for entry in dirlist.dirlist:
            if entry.statinfo.flags & XRootD.client.flags.StatInfoFlags.IS_DIR:
                worklist.append(cwd + "/" + entry.name)
            else:
                subdir = cwd[len(directory):]
                filelist[(base_url + cwd, subdir)] += entry.statinfo.size
    return filelist


def submit_dirs(schedd, assignments, dest):
    working_dir = os.path.abspath("condor_tmp")
    try:
        os.makedirs(dest)
    except OSError, oe:
        if oe.errno != errno.EEXIST:
            raise
    try:
        os.makedirs(working_dir)
    except OSError, oe:
        if oe.errno != errno.EEXIST:
            raise
    pw = pwd.getpwuid(os.geteuid())
    x509 = "/tmp/x509up_u%d" % pw.pw_uid
    arg_list = ["-n", "10"] + [assignments] + [dest]
    arg_str = classad.Function("listToArgs", arg_list)
    in_files = ["cvmfs_swissknife", "libtbb_cvmfs.so.2", "libtbbmalloc_cvmfs.so.2", "pyxrootd", "XRootD"]
    in_files = ", ".join([os.path.abspath(i) for i in in_files])
    working_dir_prefix = os.path.join(working_dir, "job_")
    ad = {'Arguments': arg_str,
          'Cmd': os.path.abspath("./cvmfs-sync"),
          'Environment': 'PATH=.:/usr/bin:/bin LD_LIBRARY_PATH=. PYTHONUNBUFFERED=1 XRD_LOGLEVEL=Debug',
          'TransferInput': in_files,
          'TransferOutput': dest.split("/")[0],
          'Out': "out",
          'Err': "err",
          'UserLog': os.path.abspath(os.path.join(working_dir, "log")),
          'Iwd': classad.Function("strcat", working_dir_prefix, classad.Attribute("ClusterId")),
          'AccountingGroup': "%s.%s" % (g_acct_grp, pw.pw_name),
          'x509userproxy': x509,
          'RequestMemory': 1024,
         }
    cluster = schedd.submit(ad)
    try:
        os.makedirs(working_dir_prefix + str(cluster))
    except OSError, oe:
        if oe.errno != errno.EEXIST:
            raise


def main():
    opts, args = parse_opts()
    dest = args[-1]
    srcs = args[:-1]
    print "Inputs to process:", ",".join(srcs)
    starttime = time.time()

    filelist = {}
    for src in srcs:
        source_filelist = []
        src_parsed = urlparse.urlparse(src)
        base_url = src_parsed.scheme + "://" + src_parsed.netloc
        directory = src_parsed.path
        filelist.update(process_dir(base_url, directory))
    total_size = sum(filelist.values())
    print "Found %d directories to process" % len(filelist)
    print "Total size: %.2fGB" % (total_size/1e9)

    assignments = []

    if not opts.dryrun:
        schedd = htcondor.Schedd()
        with schedd.transaction() as txn:
            for dirs in filelist:
                dir, subdir = dirs
                submit_dirs(schedd, dir, dest + '/' + subdir)


if __name__ == '__main__':
    main()


